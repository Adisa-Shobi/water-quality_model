{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrXv0rU9sIma"
      },
      "source": [
        "# Excercise - Creating our own custom Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJyZUDbzBTIG"
      },
      "source": [
        "This is a notebook that provides a quick overview of how to create your own custom model. You will be creating a simple model.\n",
        "You will be utilizing Keras and Tensorflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvLegMMvBZYg"
      },
      "source": [
        "## Water Quality Dataset\n",
        "\n",
        "This dataset contains water quality measurements and assessments related to potability, which is the suitability of water for human consumption. The dataset's primary objective is to provide insights into water quality parameters and assist in determining whether the water is potable or not. Each row in the dataset represents a water sample with specific attributes, and the \"Potability\" column indicates whether the water is suitable for consumption.\n",
        "\n",
        "https://www.kaggle.com/datasets/uom190346a/water-quality-and-potability?select=water_potability.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import make_classification\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "Qvnx0_dT3JEq",
        "outputId": "3e9df038-4665-45fe-ade6-a5e0379115b6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>204.890455</td>\n",
              "      <td>20791.318981</td>\n",
              "      <td>7.300212</td>\n",
              "      <td>368.516441</td>\n",
              "      <td>564.308654</td>\n",
              "      <td>10.379783</td>\n",
              "      <td>86.990970</td>\n",
              "      <td>2.963135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>129.422921</td>\n",
              "      <td>18630.057858</td>\n",
              "      <td>6.635246</td>\n",
              "      <td>NaN</td>\n",
              "      <td>592.885359</td>\n",
              "      <td>15.180013</td>\n",
              "      <td>56.329076</td>\n",
              "      <td>4.500656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.099124</td>\n",
              "      <td>224.236259</td>\n",
              "      <td>19909.541732</td>\n",
              "      <td>9.275884</td>\n",
              "      <td>NaN</td>\n",
              "      <td>418.606213</td>\n",
              "      <td>16.868637</td>\n",
              "      <td>66.420093</td>\n",
              "      <td>3.055934</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
              "0       NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
              "1  3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n",
              "2  8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n",
              "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
              "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
              "\n",
              "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "0       10.379783        86.990970   2.963135           0  \n",
              "1       15.180013        56.329076   4.500656           0  \n",
              "2       16.868637        66.420093   3.055934           0  \n",
              "3       18.436524       100.341674   4.628771           0  \n",
              "4       11.558279        31.997993   4.075075           0  "
            ]
          },
          "execution_count": 253,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#LOAD THE DATA\n",
        "data = pd.read_csv('water_potability.csv')\n",
        "\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fill in Nan values with the mean of the column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>204.890455</td>\n",
              "      <td>20791.318981</td>\n",
              "      <td>7.300212</td>\n",
              "      <td>368.516441</td>\n",
              "      <td>564.308654</td>\n",
              "      <td>10.379783</td>\n",
              "      <td>86.990970</td>\n",
              "      <td>2.963135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>129.422921</td>\n",
              "      <td>18630.057858</td>\n",
              "      <td>6.635246</td>\n",
              "      <td>364.639673</td>\n",
              "      <td>592.885359</td>\n",
              "      <td>15.180013</td>\n",
              "      <td>56.329076</td>\n",
              "      <td>4.500656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.099124</td>\n",
              "      <td>224.236259</td>\n",
              "      <td>19909.541732</td>\n",
              "      <td>9.275884</td>\n",
              "      <td>360.762904</td>\n",
              "      <td>418.606213</td>\n",
              "      <td>16.868637</td>\n",
              "      <td>66.420093</td>\n",
              "      <td>3.055934</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
              "0  3.716080  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
              "1  3.716080  129.422921  18630.057858     6.635246  364.639673    592.885359   \n",
              "2  8.099124  224.236259  19909.541732     9.275884  360.762904    418.606213   \n",
              "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
              "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
              "\n",
              "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "0       10.379783        86.990970   2.963135           0  \n",
              "1       15.180013        56.329076   4.500656           0  \n",
              "2       16.868637        66.420093   3.055934           0  \n",
              "3       18.436524       100.341674   4.628771           0  \n",
              "4       11.558279        31.997993   4.075075           0  "
            ]
          },
          "execution_count": 254,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.interpolate(inplace=True, method='linear', axis=0, limit_direction='both')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3276, 10)"
            ]
          },
          "execution_count": 255,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rows, cols = data.shape\n",
        "rows, cols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QfR0r8cGVU7"
      },
      "source": [
        "Plot the Data Appropriately"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = data.drop('Potability', axis=1).values\n",
        "y = data['Potability'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfSk1lXRYjrh",
        "outputId": "d4ab1998-023f-4932-ac61-b3da0b28932c"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_remain, X_test, y_remain, y_test = train_test_split(X, y, test_size=0.15)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_remain, y_remain, test_size=0.15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scale data using StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((2366, 9), (418, 9), (492, 9), (2366,), (418,), (492,))"
            ]
          },
          "execution_count": 258,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X=X_train)\n",
        "\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_train = np.clip(X_train, -5, 5)\n",
        "X_val = np.clip(X_val, -5, 5)\n",
        "X_test = np.clip(X_test, -5, 5)\n",
        "\n",
        "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvjIHLrcGhzc"
      },
      "source": [
        "# Each Memeber Defines their model Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Learning Rate (0.0005)\n",
        "- The choice of learning rate was informed by earlier \n",
        "training iterations where the train/test graph did not show any \n",
        "convergence between the two lines suggesting that the step \n",
        "between any two points in the gragph was too large. \n",
        "I chose a learning rate of 0.001 to ensure that the model converges to a minimum point.\n",
        "\n",
        "- With binary classification tasks, especially with the class imbalance in this dataset, \n",
        "it is important to choose a learning rate that is not too large to avoid overshooting the minimum point. 0.0005 trades off training time for accuracy.\n",
        "\n",
        "# Dropout (0.2)\n",
        "- The first iterations without dropout showed that the model was overfitting the training data in early epochs. Keeping 80% of the neurons in the hidden layers helped keep overfitting to a minimum during training. A lower dropout rate would have been too aggressive and would have resulted in underfitting.\n",
        "\n",
        "- Compining the dropout technique while and addin layers/neurons to the model helped to improve the model's performance.\n",
        "\n",
        "- Water quality data often has inherent noise and variability in measurements. This can be attributed to a number of factors including temperature which affect a range of parameters especially pH [Atlas Scientific, \"Does Temperature Affect pH?\" Atlas Scientific Blog, 2024]. Dropout helps to regularize the model and reduce overfitting to the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "FLwYoJG9jvDa"
      },
      "outputs": [],
      "source": [
        "#Model Definition by member 1\n",
        "def create_model():\n",
        "  model  = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(512, activation='relu', input_shape=(X.shape[1],)),\n",
        "\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    \n",
        "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.05)),\n",
        "    \n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    \n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.05)),\n",
        "    \n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
        "\n",
        "  model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'], )\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/apple/Documents/dev/ALU/Assignments/water-quality_model/myenv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_21\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_21\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_105 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_106 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_107 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_108 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_109 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_105 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m5,120\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_63 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_106 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_64 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_107 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_65 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_108 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_109 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">177,665</span> (694.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m177,665\u001b[0m (694.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">177,665</span> (694.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m177,665\u001b[0m (694.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "mymodel = create_model()\n",
        "mymodel.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDSPmAB9jkrG"
      },
      "source": [
        "# Start the training Process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Early Stopping (patience=5)\n",
        "- After a few training iterations, it was clear that a patience of 5 gave the model enough room to detect ensure that the graph of the train/test did not show any further inflexion points. This helped to avoid overfitting the model to the training data.\n",
        "\n",
        "- Setting restore_best_weights=True ensured that the model was saved with the best weights during training. This helped to avoid the model from being saved with weights that were overfitting or underfitting the training data.\n",
        "\n",
        "- I had attempted to a, sort of, manual early stopping by observing the graph of the train/test loss and stopping the training process when the two lines converged. However, this was not efficient and was prone to human error. Early stopping with patience=5 helped to automate this process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "OWQHapf3jlYH",
        "outputId": "f621cc01-0e17-4201-d942-b77fa0307966"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5670 - loss: 17.1251 - val_accuracy: 0.5833 - val_loss: 7.0826\n",
            "Epoch 2/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6175 - loss: 5.5476 - val_accuracy: 0.5833 - val_loss: 2.6009\n",
            "Epoch 3/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6037 - loss: 2.1560 - val_accuracy: 0.5833 - val_loss: 1.3317\n",
            "Epoch 4/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6036 - loss: 1.1851 - val_accuracy: 0.5833 - val_loss: 0.9351\n",
            "Epoch 5/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6338 - loss: 0.8539 - val_accuracy: 0.5955 - val_loss: 0.7801\n",
            "Epoch 6/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6530 - loss: 0.7330 - val_accuracy: 0.6016 - val_loss: 0.7268\n",
            "Epoch 7/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6570 - loss: 0.6879 - val_accuracy: 0.6301 - val_loss: 0.6949\n",
            "Epoch 8/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6658 - loss: 0.6636 - val_accuracy: 0.6606 - val_loss: 0.6675\n",
            "Epoch 9/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6936 - loss: 0.6411 - val_accuracy: 0.6362 - val_loss: 0.6702\n",
            "Epoch 10/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6935 - loss: 0.6364 - val_accuracy: 0.6402 - val_loss: 0.6803\n",
            "Epoch 11/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6761 - loss: 0.6361 - val_accuracy: 0.6606 - val_loss: 0.6614\n",
            "Epoch 12/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6703 - loss: 0.6365 - val_accuracy: 0.6646 - val_loss: 0.6639\n",
            "Epoch 13/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6768 - loss: 0.6366 - val_accuracy: 0.6606 - val_loss: 0.6537\n",
            "Epoch 14/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6833 - loss: 0.6258 - val_accuracy: 0.6728 - val_loss: 0.6480\n",
            "Epoch 15/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6832 - loss: 0.6298 - val_accuracy: 0.6443 - val_loss: 0.6554\n",
            "Epoch 16/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6756 - loss: 0.6359 - val_accuracy: 0.6524 - val_loss: 0.6635\n",
            "Epoch 17/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6962 - loss: 0.6147 - val_accuracy: 0.6728 - val_loss: 0.6459\n",
            "Epoch 18/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6944 - loss: 0.6191 - val_accuracy: 0.6646 - val_loss: 0.6500\n",
            "Epoch 19/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6897 - loss: 0.6207 - val_accuracy: 0.6545 - val_loss: 0.6469\n",
            "Epoch 20/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6943 - loss: 0.6154 - val_accuracy: 0.6931 - val_loss: 0.6378\n",
            "Epoch 21/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6894 - loss: 0.6253 - val_accuracy: 0.6585 - val_loss: 0.6545\n",
            "Epoch 22/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7018 - loss: 0.6117 - val_accuracy: 0.6606 - val_loss: 0.6421\n",
            "Epoch 23/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7022 - loss: 0.6102 - val_accuracy: 0.6382 - val_loss: 0.6728\n",
            "Epoch 24/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6908 - loss: 0.6194 - val_accuracy: 0.6768 - val_loss: 0.6345\n",
            "Epoch 25/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6913 - loss: 0.6258 - val_accuracy: 0.6667 - val_loss: 0.6577\n",
            "Epoch 26/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7013 - loss: 0.6040 - val_accuracy: 0.6463 - val_loss: 0.6533\n",
            "Epoch 27/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7035 - loss: 0.6010 - val_accuracy: 0.6565 - val_loss: 0.6488\n",
            "Epoch 28/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6898 - loss: 0.6220 - val_accuracy: 0.6768 - val_loss: 0.6463\n",
            "Epoch 29/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6884 - loss: 0.6159 - val_accuracy: 0.6484 - val_loss: 0.6490\n",
            "Train: 0.699, Test: 0.677\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "#fit model\n",
        "history = mymodel.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, verbose=1, callbacks=[early_stopping])\n",
        "# evaluate the model\n",
        "_, train_acc = mymodel.evaluate(X_train, y_train, verbose=0)\n",
        "_, test_acc = mymodel.evaluate(X_test, y_test, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "\n",
        "\n",
        "\n",
        "# plot training history\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculate the F1 Score of the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
            "Accuracy: 0.706\n",
            "Precision: 0.736\n",
            "Recall: 0.451\n",
            "F1 Score: 0.559\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "y_pred = (mymodel.predict(X_val) > 0.5).astype(int).reshape(-1)\n",
        "f1 = f1_score(y_val, y_pred)\n",
        "precision = precision_score(y_val, y_pred)\n",
        "recall = recall_score(y_val, y_pred)\n",
        "accuracy = mymodel.evaluate(X_val, y_val, verbose=0)[1]\n",
        "\n",
        "print(f'Accuracy: {accuracy:.3f}')\n",
        "print(f'Precision: {precision:.3f}')\n",
        "print(f'Recall: {recall:.3f}')\n",
        "print(f'F1 Score: {f1:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Save the model\n",
        "mymodel.save('model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Evaluation \n",
        "\n",
        "My model shows some interesting trade-offs in its performance. With a precision of 0.736 (meaning 73.6% of samples it identified as potable were actually potable), recall of 0.451 (meaning it only caught about 45% of the safe-to-drink water samples - imagine missing more than half of the good water!), and F1 score of 0.559 (a balanced measure combining precision and recall), it was great at avoiding false positives but missed quite a few potable water samples.\n",
        "\n",
        "A. Two main design choices led to these results. First, I used a larger network (512→256→128→64) with Adam optimizer and a lower learning rate of 0.0005. I picked this learning rate after seeing convergence issues in early tests - higher rates made the model unstable. While this made the model very precise, it was perhaps too cautious compared to my teammates' models using RMSprop.\n",
        "\n",
        "B. Second, I went with a dropout rate of 0.2 and L2 regularization (0.05) on specific layers. This came from early tests showing overfitting problems without dropout, especially given how noisy water quality data can be. While this helped maintain high precision, my teammates' different approaches to regularization achieved a better balance between precision and recall, reflected in their higher F1 scores."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
